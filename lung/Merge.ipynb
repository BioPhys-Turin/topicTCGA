{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Filippo_Valle \n",
      "last updated: Thu Jun 18 2020 \n",
      "\n",
      "CPython 3.7.6\n",
      "IPython 7.15.0\n",
      "\n",
      "pandas 1.0.4\n",
      "numpy 1.18.5\n",
      "scanpy 1.5.1\n",
      "requests 2.23.0\n",
      "json 2.0.9\n",
      "\n",
      "compiler   : GCC 7.5.0\n",
      "system     : Linux\n",
      "release    : 4.19.76-linuxkit\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   : 3c8ae8f7082ca41e4f98ab084dc707834cbe547b\n",
      "Git repo   : git@github.com:fvalle1/phd.git\n",
      "Git branch : master\n",
      "watermark 2.0.2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m  -u -n -p pandas,numpy,scanpy,requests,json -a Filippo_Valle -g -r -b -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import requests\n",
    "import json\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "Download data from [https://doi.org/10.6084/m9.figshare.5330593](https://doi.org/10.6084/m9.figshare.5330593) and [https://figshare.com/articles/Data_record_2/5330575](https://figshare.com/articles/Data_record_2/5330575) and set working_dir appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path/to/files/downloaded/\n",
    "working_dir = \"/home/jovyan/work/phd/datasets/merged/\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = filter(lambda f: \"fpkm\" in f, os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download GTEx metadata from[http://gtexportal.org](http://gtexportal.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtex=pd.read_csv(\"https://storage.googleapis.com/gtex_analysis_v8/annotations/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt\", sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download TCGA metadata using gdc API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\n",
    "    \"op\": \"and\",\n",
    "    \"content\":[\n",
    "        {\n",
    "        \"op\": \"in\",\n",
    "        \"content\":{\n",
    "            \"field\": \"cases.project.program.name\",\n",
    "            \"value\": [\"TCGA\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    ]\n",
    "}\n",
    "params = {\n",
    "    \"filters\": json.dumps(filters),\n",
    "    \"fields\": \"primary_site,disease_type,submitter_id,project.project_id\",\n",
    "    \"format\": \"TSV\",\n",
    "    \"size\": \"10000000\"\n",
    "    }\n",
    "response = requests.get(\"https://api.gdc.cancer.gov/cases\", headers = {\"Content-Type\": \"application/json\"}, params = params)\n",
    "with open(\"files.txt\",\"w\") as file:\n",
    "    file.write(response.content.decode(\"utf-8\"))\n",
    "df_tcga = pd.read_csv(\"files.txt\", sep='\\t').set_index(\"submitter_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty DataFrame to fulfill with unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df = df.append(pd.read_csv(\"data/%s\"%file, sep='\\t', index_col=0).drop('Entrez_Gene_Id',1).transpose(), sort=True)\n",
    "df = df.transpose()\n",
    "df = df.dropna(how='any', axis=0) # drop genes not always determined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.DataFrame(index=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define useful function to discriminate samples coming from GTEx and TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site(file):\n",
    "    '''\n",
    "    Returns GTEX or TCGA primary site\n",
    "    '''\n",
    "    if (\"df_gtex\" not in globals().keys()) or (\"df_tcga\" not in globals().keys()):\n",
    "        raise NotImplementedError(\"Please define datasets with gtex and tcga metadata\")\n",
    "    if 'GTEX' in file:\n",
    "        return df_gtex.at[file, 'SMTS']\n",
    "    if 'TCGA' in file:\n",
    "        return df_tcga.at[file[:12],'primary_site']\n",
    "\n",
    "def get_source(file):\n",
    "    if 'GTEX' in file:\n",
    "        return 'gtex'\n",
    "    if 'TCGA' in file:\n",
    "        return 'tcga'\n",
    "\n",
    "#https://www.researchgate.net/post/How_can_I_get_the_normal_sample_of_TCGA_data\n",
    "def get_status(file):\n",
    "    if 'GTEX' in file:\n",
    "        return 'healthy'\n",
    "    if 'TCGA' in file:\n",
    "        if (file[13:15]==\"11\") or (file[13:15]==\"10\"):\n",
    "            return 'healthy'\n",
    "        else:\n",
    "            return \"tumor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.insert(0, 'primary_site', [get_site(file) for file in df.columns])\n",
    "df_files.insert(1, 'dataset', [get_source(file) for file in df.columns])\n",
    "df_files.insert(1, 'status', [get_status(file) for file in df.columns])\n",
    "df_files.groupby([\"dataset\",\"status\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.to_csv(\"files.dat\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split / shuffle and select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.read_csv(\"files.dat\", index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unify names in different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.replace('Uterus, NOS', 'Uterus', inplace=True)\n",
    "df_files.replace('Bronchus and lung', 'Lung', inplace=True)\n",
    "df_files.replace('Liver and intrahepatic bile ducts', 'Liver', inplace=True)\n",
    "df_files.replace('Prostate gland', 'Prostate', inplace=True)\n",
    "df_files.replace('Thyroid gland', 'Thyroid', inplace=True)\n",
    "df_files.replace('Base of Tongue', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Bones, joints and articular cartilage of other and unspecified sites', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Floor of mouth', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Gum', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Hypopharynx', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Larynx', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Lip', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Oropharynx', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Other and ill-defined sites in lip, oral cavity and pharynx', 'Salivary Gland', inplace=True)\n",
    "df_files.replace('Other and unspecified parts of mouth', 'Salivary Gland', inplace=True)\n",
    "df_files[\"tissue_hd\"]=df_files[\"primary_site\"]+\"_\"+df_files[\"dataset\"]\n",
    "df_files['primary_site'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_files[df_files[\"primary_site\"]==\"Lung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[df.columns.isin(samples.index)]].to_csv(\"mainTable_merged.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.to_csv(\"files.dat\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use scanpy to filter HVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(df[samples.index].transpose(), obs=samples)\n",
    "adata_log = sc.pp.log1p(adata, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata_log, n_top_genes=3000, n_bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(adata_log, log=True, save='hvg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg = adata_log.var[adata_log.var['highly_variable']==True].index\n",
    "samples = adata_log.obs.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run hierarchical Stochastic Block Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbmtm import sbmtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sbmtm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.make_graph_from_BoW_df(df.loc[hvg, samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_graph(\"graph.xml.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
